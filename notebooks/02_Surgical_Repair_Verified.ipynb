{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Table 1 Reproduction: Multi-Model Steering Performance\n",
                "\n",
                "This notebook reproduces the results for **Table 1** in the paper. It evaluates the effectiveness of the \"Surgical Repair\" (activation steering) across three models:\n",
                "1. `microsoft/Phi-3-mini-4k-instruct`\n",
                "2. `mistralai/Mistral-7B-Instruct-v0.1`\n",
                "3. `meta-llama/Llama-3.2-3B-Instruct`\n",
                "\n",
                "For each model, we:\n",
                "1. Calibrate a steering vector using a robust technical vocabulary.\n",
                "2. Test it on a set of coherent natural language samples.\n",
                "3. Report `PPL Reduction` and `Fiedler Recovery` ($% \\lambda_2$)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "\n",
                "# Models to test\n",
                "MODELS = [\n",
                "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
                "    # Uncomment to run full suite (requires sufficient VRAM)\n",
                "    # \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
                "    # \"meta-llama/Llama-3.2-3B-Instruct\"\n",
                "]\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. SAMPLE GENERATION (Coherent) ---\n",
                "def generate_coherent_pairs(n):\n",
                "    vocab = {\n",
                "        \"subjects\": [\"The book\", \"The letter\", \"The report\", \"The message\", \"The song\", \"The code\", \"The image\", \"The file\"],\n",
                "        \"verbs\": [\"written\", \"sent\", \"reviewed\", \"received\", \"sung\", \"fixed\", \"processed\", \"saved\"],\n",
                "        \"agents\": [\"by the man\", \"by the teacher\", \"by the manager\", \"by the user\", \"by the woman\", \"by the expert\", \"by the system\", \"by the admin\"]\n",
                "    }\n",
                "    pairs = []\n",
                "    for _ in range(n):\n",
                "        s = np.random.choice(vocab[\"subjects\"])\n",
                "        v = np.random.choice(vocab[\"verbs\"])\n",
                "        a = np.random.choice(vocab[\"agents\"])\n",
                "        # Simple grammar heuristic\n",
                "        passive = f\"{s} was {v} {a}.\"\n",
                "        \n",
                "        # Active mapping (approximate)\n",
                "        v_act = v\n",
                "        if v == \"written\": v_act = \"wrote\"\n",
                "        elif v == \"sent\": v_act = \"sent\"\n",
                "        elif v == \"sung\": v_act = \"sang\"\n",
                "        elif v == \"fixed\": v_act = \"fixed\"\n",
                "        elif v == \"saved\": v_act = \"saved\"\n",
                "        \n",
                "        a_subj = a.replace(\"by \", \"\").capitalize()\n",
                "        active = f\"{a_subj} {v_act} {s.lower()}.\"\n",
                "        active = active.replace(\"The the\", \"The\") # fix artifacts\n",
                "        pairs.append((active, passive))\n",
                "    return pairs\n",
                "\n",
                "TEST_PAIRS = generate_coherent_pairs(50) # N=50 for speed in demo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 2. SPECTRAL UTILS ---\n",
                "def get_fiedler_value(adj_matrix):\n",
                "    try:\n",
                "        L = np.diag(np.sum(adj_matrix, axis=1)) - adj_matrix\n",
                "        eigvals = np.linalg.eigvalsh(L)\n",
                "        return sorted(eigvals)[1] if len(eigvals) > 1 else 0.0\n",
                "    except: return 0.0\n",
                "\n",
                "def calculate_perplexity(model, tokenizer, text):\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs, labels=inputs.input_ids)\n",
                "    return torch.exp(outputs.loss).item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 3. EXPERIMENT LOOP ---\n",
                "RESULTS = []\n",
                "\n",
                "for model_name in MODELS:\n",
                "    print(f\"\\nProcessing {model_name}...\")\n",
                "    try:\n",
                "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
                "        # Fix padding\n",
                "        if tokenizer.pad_token is None: \n",
                "            tokenizer.pad_token = tokenizer.eos_token\n",
                "            \n",
                "        model = AutoModelForCausalLM.from_pretrained(\n",
                "            model_name, \n",
                "            torch_dtype=torch.float16, \n",
                "            device_map=\"auto\",\n",
                "            attn_implementation=\"eager\"\n",
                "        )\n",
                "    except Exception as e:\n",
                "        print(f\"Skipping {model_name} (Load Error): {e}\")\n",
                "        continue\n",
                "\n",
                "    # CALIBRATE STEERING\n",
                "    LAYER_IDX = 2\n",
                "    tech_vocab = [\"The system processed the data.\", \"The data was processed by the system.\"]\n",
                "    # (Simplified calibration for demo - ideally utilize robust set)\n",
                "    \n",
                "    def get_mean_hidden(text):\n",
                "        inp = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
                "        with torch.no_grad(): out = model(**inp, output_hidden_states=True)\n",
                "        return out.hidden_states[LAYER_IDX+1].mean(dim=1).mean(dim=0)\n",
                "    \n",
                "    v_act = get_mean_hidden(tech_vocab[0])\n",
                "    v_pas = get_mean_hidden(tech_vocab[1])\n",
                "    steering_vector = v_act - v_pas\n",
                "    \n",
                "    # RUN TEST\n",
                "    ppl_bases, ppl_steers = [], []\n",
                "    f_bases, f_steers, f_actives = [], [], []\n",
                "    \n",
                "    # Define Hook\n",
                "    alpha = 0.2\n",
                "    def steer_hook(module, inp, out):\n",
                "        if isinstance(out, tuple):\n",
                "            h = out[0]\n",
                "            v = steering_vector.view(1, 1, -1).to(h.dtype)\n",
                "            return (h + alpha * v,) + out[1:]\n",
                "        return out + alpha * steering_vector.view(1, 1, -1).to(out.dtype)\n",
                "    \n",
                "    for active, passive in TEST_PAIRS:\n",
                "        # 1. Baseline Passive\n",
                "        ppl_base = calculate_perplexity(model, tokenizer, passive)\n",
                "        # Get Fiedler\n",
                "        inp = tokenizer(passive, return_tensors=\"pt\").to(model.device)\n",
                "        with torch.no_grad(): out = model(**inp, output_attentions=True)\n",
                "        adj = out.attentions[LAYER_IDX][0].mean(dim=0).float().cpu().numpy()\n",
                "        f_base = get_fiedler_value(adj)\n",
                "\n",
                "        # 2. Active Reference\n",
                "        inp_a = tokenizer(active, return_tensors=\"pt\").to(model.device)\n",
                "        with torch.no_grad(): out_a = model(**inp_a, output_attentions=True)\n",
                "        adj_a = out_a.attentions[LAYER_IDX][0].mean(dim=0).float().cpu().numpy()\n",
                "        f_active_val = get_fiedler_value(adj_a)\n",
                "        \n",
                "        # 3. Steered Passive\n",
                "        h = model.model.layers[LAYER_IDX].register_forward_hook(steer_hook)\n",
                "        ppl_steer = calculate_perplexity(model, tokenizer, passive)\n",
                "        # Get Fiedler Steered\n",
                "        inp = tokenizer(passive, return_tensors=\"pt\").to(model.device)\n",
                "        with torch.no_grad(): out = model(**inp, output_attentions=True)\n",
                "        adj = out.attentions[LAYER_IDX][0].mean(dim=0).float().cpu().numpy()\n",
                "        f_steer = get_fiedler_value(adj)\n",
                "        h.remove()\n",
                "        \n",
                "        # Store\n",
                "        ppl_bases.append(ppl_base)\n",
                "        ppl_steers.append(ppl_steer)\n",
                "        f_bases.append(f_base)\n",
                "        f_steers.append(f_steer)\n",
                "        f_actives.append(f_active_val)\n",
                "        \n",
                "    # Aggregate\n",
                "    mean_ppl_base = np.mean(ppl_bases)\n",
                "    mean_ppl_steer = np.mean(ppl_steers)\n",
                "    mean_f_base = np.mean(f_bases)\n",
                "    mean_f_steer = np.mean(f_steers)\n",
                "    mean_f_act = np.mean(f_actives)\n",
                "    \n",
                "    # Metrics\n",
                "    ppl_gain = mean_ppl_base - mean_ppl_steer\n",
                "    pct_gain = (ppl_gain / mean_ppl_base) * 100\n",
                "    loss_gap = mean_f_act - mean_f_base\n",
                "    recovered = mean_f_steer - mean_f_base\n",
                "    rec_pct = (recovered / loss_gap) * 100 if loss_gap > 0 else 0\n",
                "    \n",
                "    print(f\"  Base PPL: {mean_ppl_base:.2f} -> Steered: {mean_ppl_steer:.2f} (Gain +{pct_gain:.1f}%)\")\n",
                "    print(f\"  Fiedler: {mean_f_base:.3f} -> {mean_f_steer:.3f} (Target {mean_f_act:.3f}) (Recov {rec_pct:.1f}%)\")\n",
                "    \n",
                "    RESULTS.append({\n",
                "        \"Model\": model_name,\n",
                "        \"Base PPL\": mean_ppl_base,\n",
                "        \"Steered PPL\": mean_ppl_steer,\n",
                "        \"Recov %\": rec_pct,\n",
                "        \"PPL Gain %\": pct_gain\n",
                "    })"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 4. DISPLAY TABLE ---\n",
                "import pandas as pd\n",
                "df = pd.DataFrame(RESULTS)\n",
                "display(df)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}